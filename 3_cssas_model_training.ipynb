{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cssas-model_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ziatdinovmax/CSSAS-DML/blob/master/3_cssas_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxl8J3rGuoJ5",
        "colab_type": "text"
      },
      "source": [
        "## Model training\n",
        "\n",
        "Prepared by Maxim Ziatdinov (October 2019)\n",
        "\n",
        "\n",
        "---\n",
        "This notebook loads training data data and performs a training of a fully convolutional neural network for finding \"particles\" in noisy microscopy data. It has an option of starting the training with the weights of the already trained model, which may save some time.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mnRYyUb3aXl",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Import modules\n",
        "# Data manipulation and plotting\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# Neural networks\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBOJmDkM3Px2",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Load custom modules { form-width: \"20%\" }\n",
        "\n",
        "def load_torchmodel(weights_path, model):\n",
        "    '''Loads saved weights into a model'''\n",
        "    if torch.cuda.device_count() > 0:\n",
        "        checkpoint = torch.load(weights_path)\n",
        "    else:\n",
        "        checkpoint = torch.load(weights_path, map_location='cpu')\n",
        "    model.load_state_dict(checkpoint)\n",
        "    return model\n",
        "    \n",
        "class conv2dblock(nn.Module):\n",
        "    '''\n",
        "    Creates a block consisting of convolutional\n",
        "    layer, leaky relu and (optionally) dropout and\n",
        "    batch normalization\n",
        "    '''\n",
        "    def __init__(self, input_channels, output_channels,\n",
        "                 kernel_size=3, stride=1, padding=1,\n",
        "                 use_batchnorm=False, lrelu_a=0.01,\n",
        "                 dropout_=0):\n",
        "        '''\n",
        "        Args:\n",
        "            input_channels: number of channels in the previous/input layer\n",
        "            output_channels: number of the output channels for the present layer\n",
        "            kernel_size: size (in pixels) of convolutional filter\n",
        "            stride: value of convolutional filter stride\n",
        "            padding: value of padding at the edges\n",
        "            use_batchnorm (boolean): usage of batch normalization\n",
        "            lrelu_a: value of alpha parameter in leaky/paramteric ReLU activation\n",
        "            dropout_: value of dropout\n",
        "        '''\n",
        "        super(conv2dblock, self).__init__()\n",
        "        block = []\n",
        "        block.append(nn.Conv2d(input_channels,\n",
        "                               output_channels,\n",
        "                               kernel_size=kernel_size,\n",
        "                               stride=stride,\n",
        "                               padding=padding))\n",
        "        if dropout_ > 0:\n",
        "            block.append(nn.Dropout(dropout_))\n",
        "        block.append(nn.LeakyReLU(negative_slope=lrelu_a))\n",
        "        if use_batchnorm:\n",
        "            block.append(nn.BatchNorm2d(output_channels))\n",
        "        self.block = nn.Sequential(*block)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''Forward path'''\n",
        "        output = self.block(x)\n",
        "        return output\n",
        "\n",
        "class dilation_block(nn.Module):\n",
        "    '''\n",
        "    Creates a block with dilated convolutional\n",
        "    layers (aka atrous convolutions)\n",
        "    '''\n",
        "    def __init__(self, input_channels, output_channels,\n",
        "                 dilation_values, padding_values,\n",
        "                 kernel_size=3, stride=1, lrelu_a=0.01,\n",
        "                 use_batchnorm=False, dropout_=0):\n",
        "        '''\n",
        "        Args:\n",
        "            input_channels: number of channels in the previous/input layer\n",
        "            output_channels: number of the output channels for the present layer\n",
        "            dilation_values: list of dilation rates for convolution operation\n",
        "            kernel_size: size (in pixels) of convolutional filter\n",
        "            stride: value of convolutional filter stride\n",
        "            padding: value of padding at the edges\n",
        "            use_batchnorm (boolean): usage of batch normalization\n",
        "            lrelu_a: value of alpha parameter in leaky/paramteric ReLU activation\n",
        "            dropout_: value of dropout\n",
        "            '''\n",
        "        super(dilation_block, self).__init__()\n",
        "        atrous_module = []\n",
        "        for idx, (dil, pad) in enumerate(zip(dilation_values, padding_values)):\n",
        "            input_channels = output_channels if idx > 0 else input_channels\n",
        "            atrous_module.append(nn.Conv2d(input_channels,\n",
        "                                           output_channels,\n",
        "                                           kernel_size=kernel_size,\n",
        "                                           stride=stride,\n",
        "                                           padding=pad,\n",
        "                                           dilation=dil,\n",
        "                                           bias=True))\n",
        "            if dropout_ > 0:\n",
        "                atrous_module.append(nn.Dropout(dropout_))\n",
        "            atrous_module.append(nn.LeakyReLU(negative_slope=lrelu_a))\n",
        "            if use_batchnorm:\n",
        "                atrous_module.append(nn.BatchNorm2d(output_channels))\n",
        "        self.atrous_module = nn.Sequential(*atrous_module)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''Forward path'''\n",
        "        atrous_layers = []\n",
        "        for conv_layer in self.atrous_module:\n",
        "            x = conv_layer(x)\n",
        "            atrous_layers.append(x.unsqueeze(-1))\n",
        "        return torch.sum(torch.cat(atrous_layers, dim=-1), dim=-1)\n",
        "\n",
        "class upsample_block(nn.Module):\n",
        "    '''\n",
        "    Defines upsampling block performed either with\n",
        "    bilinear interpolation followed by 1-by-1\n",
        "    convolution or with a transposed convolution\n",
        "    '''\n",
        "    def __init__(self, input_channels, output_channels,\n",
        "                 mode='interpolate', kernel_size=1,\n",
        "                 stride=1, padding=0):\n",
        "        '''\n",
        "        Args:\n",
        "            input_channels: number of channels in the previous/input layer\n",
        "            output_channels: number of the output channels for the present layer\n",
        "            mode: upsampling mode (default: 'interpolate')\n",
        "            kernel_size: size (in pixels) of convolutional filter\n",
        "            stride: value of convolutional filter stride\n",
        "            padding: value of padding at the edges\n",
        "            '''\n",
        "        super(upsample_block, self).__init__()\n",
        "        self.mode = mode\n",
        "        self.conv = nn.Conv2d(\n",
        "            input_channels, output_channels,\n",
        "            kernel_size = kernel_size,\n",
        "            stride = stride, padding = padding)\n",
        "        self.conv_t = nn.ConvTranspose2d(\n",
        "            input_channels, output_channels,\n",
        "            kernel_size=2, stride=2, padding = 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''Defines a forward path'''\n",
        "        if self.mode == 'interpolate':\n",
        "            x = F.interpolate(\n",
        "                x, scale_factor=2,\n",
        "                mode='bilinear', align_corners=False)\n",
        "            return self.conv(x)\n",
        "        return self.conv_t(x)\n",
        "\n",
        "\n",
        "\n",
        "class atomsegnet(nn.Module):\n",
        "    '''\n",
        "    Builds  a fully convolutional neural network model\n",
        "    '''\n",
        "    def __init__(self, nb_classes=1, nb_filters=32):\n",
        "        '''\n",
        "        Args:\n",
        "            nb_filters: number of filters in the first convolutional layer\n",
        "        '''\n",
        "        super(atomsegnet, self).__init__()\n",
        "        self.pxac = 'sigmoid' if nb_classes < 2 else 'softmax'\n",
        "        self.c1 = conv2dblock(1, nb_filters)\n",
        "        \n",
        "        self.c2 = nn.Sequential(conv2dblock(nb_filters,\n",
        "                                            nb_filters*2),\n",
        "                                conv2dblock(nb_filters*2,\n",
        "                                            nb_filters*2))\n",
        "        \n",
        "        self.c3 = nn.Sequential(conv2dblock(nb_filters*2,\n",
        "                                            nb_filters*4,\n",
        "                                            dropout_=0.3),\n",
        "                                conv2dblock(nb_filters*4,\n",
        "                                            nb_filters*4,\n",
        "                                            dropout_=0.3))\n",
        "        \n",
        "        self.bn = dilation_block(nb_filters*4,\n",
        "                                 nb_filters*8,\n",
        "                                 dilation_values=[2, 4, 6],\n",
        "                                 padding_values=[2, 4, 6],\n",
        "                                 dropout_=0.5)\n",
        "        \n",
        "        self.upsample_block1 = upsample_block(nb_filters*8,\n",
        "                                              nb_filters*4)\n",
        "        \n",
        "        self.c4 = nn.Sequential(conv2dblock(nb_filters*8,\n",
        "                                            nb_filters*4,\n",
        "                                            dropout_=0.3),\n",
        "                                conv2dblock(nb_filters*4,\n",
        "                                            nb_filters*4,\n",
        "                                            dropout_=0.3))\n",
        "        \n",
        "        self.upsample_block2 = upsample_block(nb_filters*4,\n",
        "                                              nb_filters*2)\n",
        "        \n",
        "        self.c5 = nn.Sequential(conv2dblock(nb_filters*4,\n",
        "                                            nb_filters*2),\n",
        "                                conv2dblock(nb_filters*2,\n",
        "                                            nb_filters*2))\n",
        "        \n",
        "        self.upsample_block3 = upsample_block(nb_filters*2,\n",
        "                                              nb_filters)\n",
        "        \n",
        "        self.c6 = conv2dblock(nb_filters*2,\n",
        "                              nb_filters)\n",
        "        \n",
        "        self.px = nn.Conv2d(nb_filters,\n",
        "                            nb_classes,\n",
        "                            kernel_size=1,\n",
        "                            stride=1,\n",
        "                            padding=0)\n",
        "               \n",
        "    def forward(self, x):\n",
        "        '''Defines a forward path'''\n",
        "        # Contracting path\n",
        "        c1 = self.c1(x)\n",
        "        d1 = F.max_pool2d(c1, kernel_size=2, stride=2)\n",
        "        c2 = self.c2(d1)\n",
        "        d2 = F.max_pool2d(c2, kernel_size=2, stride=2)\n",
        "        c3 = self.c3(d2)\n",
        "        d3 = F.max_pool2d(c3, kernel_size=2, stride=2)\n",
        "        # Atrous convolutions\n",
        "        bn = self.bn(d3)\n",
        "        # Expanding path\n",
        "        u3 = self.upsample_block1(bn)\n",
        "        u3 = torch.cat([c3, u3], dim=1)\n",
        "        u3 = self.c4(u3)\n",
        "        u2 = self.upsample_block2(u3)\n",
        "        u2 = torch.cat([c2, u2], dim=1)\n",
        "        u2 = self.c5(u2)\n",
        "        u1 = self.upsample_block3(u2)\n",
        "        u1 = torch.cat([c1, u1], dim=1)\n",
        "        u1 = self.c6(u1)\n",
        "        # pixel-wise classification\n",
        "        px = self.px(u1)\n",
        "        if self.pxac == 'sigmoid':\n",
        "            output = torch.sigmoid(px)\n",
        "        elif self.pxac == 'softmax':\n",
        "            output = F.log_softmax(px, dim=1)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C51qVIWcqXFZ",
        "colab_type": "text"
      },
      "source": [
        "## Load training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKhRWuP7oP_1",
        "colab_type": "text"
      },
      "source": [
        "Mount google drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miMprJZ-oOlz",
        "colab_type": "code",
        "outputId": "22328a39-c87b-43a8-c661-a5f278b60319",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdtDD4HfjQTu",
        "colab_type": "text"
      },
      "source": [
        "Load training data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_Zm9NUujU5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# specify directory with data in google drive\n",
        "datadir = 'drive/Shared drives/CSSAS-ML/training_data'\n",
        "\n",
        "images_all = np.load(\n",
        "    os.path.join(datadir, 'pnnl_training_images.npy'), allow_pickle=True)[()]\n",
        "labels_all = np.load(\n",
        "    os.path.join(datadir, 'pnnl_training_labels.npy'), allow_pickle=True)[()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ajlbEMaSa-ZE"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wXMVUvR1Dsrm",
        "colab": {}
      },
      "source": [
        "# We may start using the weights of the already trained model\n",
        "use_pretrained = True\n",
        "pretrained_weights_path = 'drive/Shared drives/CSSAS-ML/pretrained/pnnl-100mL-part2-8.pt'\n",
        "# Initialize our model\n",
        "if use_pretrained:  \n",
        "    model = atomsegnet()\n",
        "    model = load_torchmodel(pretrained_weights_path, model)\n",
        "else:\n",
        "    model = atomsegnet()\n",
        "# move our model to GPU\n",
        "model.cuda()\n",
        "# specify loss function.\n",
        "criterion = torch.nn.BCELoss()\n",
        "# specify optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DfrI6ZgEEdcy",
        "outputId": "5304c0b6-f1d5-4556-b8b0-e5fd98e039b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        }
      },
      "source": [
        "batch_size = 32 # number of images in one batch\n",
        "epochs = 500 # Number of epochs (here 1 epoch == 1 batch)\n",
        "save_weights = 100 # save weights every n-th epoch.\n",
        "print_loss = 10 # print loss every m-th epoch.\n",
        "savedir = 'drive/Shared drives/CSSAS-ML/saved_models/' # dir to save results\n",
        "# Start training\n",
        "train_losses = []\n",
        "for e in range(epochs):  \n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    # Generate batch of images with corresponding ground truth\n",
        "    batch_num = np.random.randint(0, len(images_all))\n",
        "    images = images_all[batch_num][:batch_size]\n",
        "    labels = labels_all[batch_num][:batch_size]\n",
        "    # Transform images and ground truth to torch tensors and move to GPU\n",
        "    images = torch.from_numpy(images).float()\n",
        "    labels = torch.from_numpy(labels).float()\n",
        "    images, labels = images.cuda(), labels.cuda() \n",
        "    # Forward --> Backward --> Optimize\n",
        "    optimizer.zero_grad() \n",
        "    prob = model.forward(images)\n",
        "    loss = criterion(prob, labels)\n",
        "    running_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_losses.append(running_loss)\n",
        "    # Print statistics\n",
        "    if e == 0 or (e+1)%print_loss == 0:\n",
        "        print('Epoch', str(e+1) + 4*'.', 'Training loss:',\n",
        "              str(np.around((running_loss), decimals=8)))\n",
        "    # Save model weights\n",
        "    if (e+1)%save_weights == 0:\n",
        "        torch.save(model.state_dict(), \n",
        "                   os.path.join(savedir, 'pnnl-model-1-epoch-{}'.format(e+1)+'.pt'))\n",
        "# Save final weights\n",
        "torch.save(model.state_dict(), os.path.join(savedir, 'pnnl-model-1.pt'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1.... Training loss: 0.09920368\n",
            "Epoch 10.... Training loss: 0.09229717\n",
            "Epoch 20.... Training loss: 0.08059397\n",
            "Epoch 30.... Training loss: 0.08181105\n",
            "Epoch 40.... Training loss: 0.08275608\n",
            "Epoch 50.... Training loss: 0.07388188\n",
            "Epoch 60.... Training loss: 0.07447903\n",
            "Epoch 70.... Training loss: 0.07356308\n",
            "Epoch 80.... Training loss: 0.07555639\n",
            "Epoch 90.... Training loss: 0.06890152\n",
            "Epoch 100.... Training loss: 0.06407918\n",
            "Epoch 110.... Training loss: 0.07525395\n",
            "Epoch 120.... Training loss: 0.06116368\n",
            "Epoch 130.... Training loss: 0.0703219\n",
            "Epoch 140.... Training loss: 0.06796927\n",
            "Epoch 150.... Training loss: 0.06809495\n",
            "Epoch 160.... Training loss: 0.05940093\n",
            "Epoch 170.... Training loss: 0.07387992\n",
            "Epoch 180.... Training loss: 0.06844976\n",
            "Epoch 190.... Training loss: 0.06811372\n",
            "Epoch 200.... Training loss: 0.07631534\n",
            "Epoch 210.... Training loss: 0.06120227\n",
            "Epoch 220.... Training loss: 0.06710134\n",
            "Epoch 230.... Training loss: 0.06045723\n",
            "Epoch 240.... Training loss: 0.06666834\n",
            "Epoch 250.... Training loss: 0.0593725\n",
            "Epoch 260.... Training loss: 0.06740435\n",
            "Epoch 270.... Training loss: 0.06642693\n",
            "Epoch 280.... Training loss: 0.06247443\n",
            "Epoch 290.... Training loss: 0.06617027\n",
            "Epoch 300.... Training loss: 0.06201242\n",
            "Epoch 310.... Training loss: 0.06346117\n",
            "Epoch 320.... Training loss: 0.05736523\n",
            "Epoch 330.... Training loss: 0.07410573\n",
            "Epoch 340.... Training loss: 0.06411292\n",
            "Epoch 350.... Training loss: 0.06698265\n",
            "Epoch 360.... Training loss: 0.06841356\n",
            "Epoch 370.... Training loss: 0.06570425\n",
            "Epoch 380.... Training loss: 0.06195462\n",
            "Epoch 390.... Training loss: 0.06514753\n",
            "Epoch 400.... Training loss: 0.06648488\n",
            "Epoch 410.... Training loss: 0.06479153\n",
            "Epoch 420.... Training loss: 0.06569832\n",
            "Epoch 430.... Training loss: 0.06983843\n",
            "Epoch 440.... Training loss: 0.07272043\n",
            "Epoch 450.... Training loss: 0.05475495\n",
            "Epoch 460.... Training loss: 0.06183296\n",
            "Epoch 470.... Training loss: 0.06350063\n",
            "Epoch 480.... Training loss: 0.06371988\n",
            "Epoch 490.... Training loss: 0.06693701\n",
            "Epoch 500.... Training loss: 0.06852085\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU6H22wTs89a",
        "colab_type": "text"
      },
      "source": [
        "Plot losses:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8lXBZhSsxgT",
        "colab_type": "code",
        "outputId": "6b754d96-6f98-4017-9396-5c28581a27ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "plt.plot(train_losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAMIpXFkXs13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}